## set user agent (NB: Important!)
## fill in correct details, uncomment, and run this line before scraping
##
httr::set_config(httr::user_agent("arne.langlet@univie.ac.at;  maripoldata.eu"))
#
### ------------------------------------------------------------------------ ###
# number of pages to scrape
npages <- as.integer(length(url_list))
# create progress bar
pb <- txtProgressBar(min = 1, max = npages, initial = 1, char = "-", width = 60, style = 3)
#empty list for data frames
dfs <- list()
# main loop over 'npages'
for (i in 1:npages) {
final.url <- url_list[i]
#update progress bar
# setTxtProgressBar(pb, i)
# build file name
file.name <- paste0("./io_cooperation/unep_page", i, "---", Sys.Date(), ".html")
# avoid re-downloading by checking for files before downloading
if (file.exists(file.name)) {
page <- read_html(file.name)
} else {
tmp <- GET(final.url)
tmp <- content(tmp, type = "text")
write(tmp, file.name)
page <- read_html(tmp)
}
# extract data
titles <- page %>%
html_nodes(".font-bold") %>%
html_text(trim = T)
links <- page %>%
html_nodes('.max-w-8xl a') %>%
html_attr("href")
texts <- page %>%
html_nodes(".max-w-8xl") %>%
html_text(trim=T)
# plow data into dataframe
df <- data.frame(
title = titles[5],
# date = dates,
# byline = authors,
#  excerpt = excerpts,
link = paste(links[grepl("https", links)], collapse = ", "),
text = texts[1]
)
# put page 'i' dataframe into the list
dfs[[i]] <- df
}
library(rvest)
tmp <- GET(final.url)
# Arne Langlet
library(rvest)
library(tidyverse)
library(data.table)
### ------------------------------------------------------------------------ ###
##
## set user agent (NB: Important!)
## fill in correct details, uncomment, and run this line before scraping
##
httr::set_config(httr::user_agent("arne.langlet@univie.ac.at;  maripoldata.eu"))
#
### ------------------------------------------------------------------------ ###
# number of pages to scrape
npages <- as.integer(length(url_list))
# create progress bar
pb <- txtProgressBar(min = 1, max = npages, initial = 1, char = "-", width = 60, style = 3)
#empty list for data frames
dfs <- list()
# main loop over 'npages'
for (i in 1:npages) {
final.url <- url_list[i]
#update progress bar
# setTxtProgressBar(pb, i)
# build file name
file.name <- paste0("./io_cooperation/unep_page", i, "---", Sys.Date(), ".html")
# avoid re-downloading by checking for files before downloading
if (file.exists(file.name)) {
page <- read_html(file.name)
} else {
tmp <- GET(final.url)
tmp <- content(tmp, type = "text")
write(tmp, file.name)
page <- read_html(tmp)
}
# extract data
titles <- page %>%
html_nodes(".font-bold") %>%
html_text(trim = T)
links <- page %>%
html_nodes('.max-w-8xl a') %>%
html_attr("href")
texts <- page %>%
html_nodes(".max-w-8xl") %>%
html_text(trim=T)
# plow data into dataframe
df <- data.frame(
title = titles[5],
# date = dates,
# byline = authors,
#  excerpt = excerpts,
link = paste(links[grepl("https", links)], collapse = ", "),
text = texts[1]
)
# put page 'i' dataframe into the list
dfs[[i]] <- df
}
View(df)
# number of pages to scrape
npages <- as.integer(length(url_list))
# create progress bar
pb <- txtProgressBar(min = 1, max = npages, initial = 1, char = "-", width = 60, style = 3)
#empty list for data frames
dfs <- list()
# main loop over 'npages'
for (i in 1:npages) {
final.url <- url_list[i]
#update progress bar
# setTxtProgressBar(pb, i)
# build file name
file.name <- paste0("./io_cooperation/unep_page", i, "---", Sys.Date(), ".html")
# avoid re-downloading by checking for files before downloading
if (file.exists(file.name)) {
page <- read_html(file.name)
} else {
tmp <- GET(final.url)
tmp <- content(tmp, type = "text")
write(tmp, file.name)
page <- read_html(tmp)
}
# extract data
titles <- page %>%
html_nodes(".font-bold") %>%
html_text(trim = T)
links <- page %>%
html_nodes('.max-w-8xl a') %>%
html_attr("href")
texts <- page %>%
html_nodes(".max-w-8xl") %>%
html_text(trim=T)
# plow data into dataframe
df <- data.frame(
title = titles[5],
# date = dates,
# byline = authors,
#  excerpt = excerpts,
link = paste(links[grepl("https", links)], collapse = ", "),
text = texts[1]
)
# put page 'i' dataframe into the list
dfs[[i]] <- df
}
library(httr)
#empty list for data frames
dfs <- list()
# main loop over 'npages'
for (i in 1:npages) {
final.url <- url_list[i]
#update progress bar
# setTxtProgressBar(pb, i)
# build file name
file.name <- paste0("./io_cooperation/unep_page", i, "---", Sys.Date(), ".html")
# avoid re-downloading by checking for files before downloading
if (file.exists(file.name)) {
page <- read_html(file.name)
} else {
tmp <- GET(final.url)
tmp <- content(tmp, type = "text")
write(tmp, file.name)
page <- read_html(tmp)
}
# extract data
titles <- page %>%
html_nodes(".font-bold") %>%
html_text(trim = T)
links <- page %>%
html_nodes('.max-w-8xl a') %>%
html_attr("href")
texts <- page %>%
html_nodes(".max-w-8xl") %>%
html_text(trim=T)
# plow data into dataframe
df <- data.frame(
title = titles[5],
# date = dates,
# byline = authors,
#  excerpt = excerpts,
link = paste(links[grepl("https", links)], collapse = ", "),
text = texts[1]
)
# put page 'i' dataframe into the list
dfs[[i]] <- df
}
# stack all page dataframes together
out <- as.data.frame(rbindlist(dfs))
# add a variable for the date of collection (R-Bloggers is updated constantly!)
out$collection_date <- Sys.Date()
out$text <- str_to_lower(out$text)
out$text
write.csv(out, file = "out_unep.csv")
View(out)
url_list[25]
url_list[-25]
url_list <- url_list[-25]
# number of pages to scrape
npages <- as.integer(length(url_list))
# create progress bar
pb <- txtProgressBar(min = 1, max = npages, initial = 1, char = "-", width = 60, style = 3)
#empty list for data frames
dfs <- list()
# main loop over 'npages'
for (i in 1:npages) {
final.url <- url_list[i]
#update progress bar
# setTxtProgressBar(pb, i)
# build file name
file.name <- paste0("./io_cooperation/unep_page", i, "---", Sys.Date(), ".html")
# avoid re-downloading by checking for files before downloading
if (file.exists(file.name)) {
page <- read_html(file.name)
} else {
tmp <- GET(final.url)
tmp <- content(tmp, type = "text")
write(tmp, file.name)
page <- read_html(tmp)
}
# extract data
## for url [25]
# titles <- page %>%
#   html_nodes(".font-bold") %>%
#   html_text(trim = T)
#
# links <- page %>%
#   html_nodes('.max-w-8xl a') %>%
#   html_attr("href")
#
# texts <- page %>%
#   html_nodes(".max-w-8xl") %>%
#   html_text(trim=T)
titles <- page %>%
html_nodes(".article_header_meta_wrap") %>%
html_text(trim = T)
links <- page %>%
html_nodes('.content_wrap a') %>%
html_attr("href")
texts <- page %>%
html_nodes(".content_wrap") %>%
html_text(trim=T)
# plow data into dataframe
df <- data.frame(
title = titles,
# date = dates,
# byline = authors,
#  excerpt = excerpts,
link = paste(links[grepl("https", links)], collapse = ", "),
text = texts
)
# put page 'i' dataframe into the list
dfs[[i]] <- df
}
# stack all page dataframes together
out <- as.data.frame(rbindlist(dfs))
# add a variable for the date of collection (R-Bloggers is updated constantly!)
out$collection_date <- Sys.Date()
out$text <- str_to_lower(out$text)
write.csv(out, file = "out_unep.csv")
View(out)
View(dfs)
library(igraph)
igo <-       str_to_lower(c("NEAFC", "ISA",
"HELCOM", "CPPS", "NAFO",
"NPFC","OSPAR", "SPREP", "WCPFC", "AALCO",
"ICES", "Commonwealth", "Iccat", "SPC", "IPBES", "IATTC", "Medfund", "GCF", "SEAFO",
"Pacific Island Forum", "SICA", "WTO", "Nauru Agreement", "ILO", "IWC", "ATS",
"Benguela", "PEMSEA", "IPCC", "CCAMLR", "APFIC",
"GLFC", "IOTC", "IPHC", "NASCO", "PSC",
"SEAFDEC", "NACA", "PICES", "IAEA", "WMO", "world bank"))
ioc <- read.csv("out_ioc.csv")
DT <- as.data.table(ioc)
x <- c()
ioc$text[1]
for (i in igo){ x = c(x, igo = length(grep(i, DT$text)))}
df_ioc <- data.frame(ioc = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_ioc) <- igo
net_ioc <- graph_from_incidence_matrix(df_ioc)
plot(net_ioc)
isa <- read.csv("out_unep.csv")
unep <- read.csv("out_unep.csv")
DT <- as.data.table(unep)
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df <- data.frame(unep = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df) <- igo
net <- graph_from_incidence_matrix(df)
plot(net)
ioc <- read.csv("out_ioc.csv")
DT <- as.data.table(ioc)
x <- c()
ioc$text[1]
for (i in igo){ x = c(x, igo = length(grep(i, DT$text)))}
df_ioc <- data.frame(ioc = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_ioc) <- igo
isa <- read.csv("out_isa.csv")
DT <- as.data.table(isa)
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df <- data.frame(isa = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_isa) <- igo
isa <- read.csv("out_isa.csv")
DT <- as.data.table(isa)
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_isa <- data.frame(isa = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_isa) <- igo
unep <- read.csv("out_unep.csv")
DT <- as.data.table(unep)
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_unep <- data.frame(unep = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_unep) <- igo
View(df)
View(df_ioc)
ioc <- read.csv("out_ioc.csv")
DT <- as.data.table(ioc)
x <- c()
ioc$text[1]
for (i in igo){ x = c(x, igo = length(grep(i, DT$text)))}
df_ioc <- data.frame(ioc = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_ioc) <- igo
isa <- read.csv("out_isa.csv")
DT <- as.data.table(isa)
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_isa <- data.frame(isa = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_isa) <- igo
unep <- read.csv("out_unep.csv")
DT <- as.data.table(unep)
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_unep <- data.frame(unep = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_unep) <- igo
View(df_ioc)
View(df_isa)
inc_net <- cbind(df_ioc, df_isa, df_unep)
View(inc_net)
net <- graph_from_incidence_matrix(df)
plot(net)
View(inc_net)
View(net)
net <- graph_from_incidence_matrix(inc_net)
plot(net)
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
for (i in igo){ x = c(x, igo = length(grep(i, DT$text)))}
for (i in igo){ xx = c(xx, igo = length(grep(i, DT$link)))}
xx <- c()
for (i in igo){ xx = c(xx, igo = length(grep(i, DT$link)))}
df_ioc <- data.frame(ioc = matrix(unlist(x, xx), nrow=length(x,xx), byrow=T))
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_ioc2 <- data.frame(ioc = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_ioc2) <- igo
View(df_ioc)
View(df_ioc2)
View(df_ioc)
View(df_ioc)
View(df_ioc2)
ndf = pd.concat([df_ioc,df_ioc2]).groupby('ioc').sum()
dt3 <- data.frame(rbind(df_ioc, df_ioc2))
View(dt3)
bind_rows(df_ioc, df_ioc2) %>% group_by(ioc) %>%
summarise_all(sum)
df_ioc <- cbind(df_ioc1, df_ioc2)
ioc <- read.csv("out_ioc.csv")
DT <- as.data.table(ioc)
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$text)))}
df_ioc1 <- data.frame(ioc = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_ioc1) <- igo
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_ioc2 <- data.frame(ioc = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_ioc2) <- igo
df_ioc <- cbind(df_ioc1, df_ioc2)
View(df)
View(df_ioc)
df_ioc %>% mutate(ioc = ioc + ioc)
df_ioc %>% mutate(ioc = ioc)
df_ioc %>% mutate(ioc_final = ioc + ioc)
df_ioc %>% mutate(ioc_final = ioc*2)
ioc <- read.csv("out_ioc.csv")
DT <- as.data.table(ioc)
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$text)))}
df_ioc1 <- data.frame(ioc1 = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_ioc1) <- igo
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_ioc2 <- data.frame(ioc1 = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_ioc2) <- igo
df_ioc <- cbind(df_ioc1, df_ioc2)
df_ioc %>% mutate(ioc_final = ioc1 + ioc2)
df_ioc %>% mutate(ioc_final = ioc1)
mutate(df_ioc, a = ioc1)
df_ioc$ioc1
ioc <- read.csv("out_ioc.csv")
DT <- as.data.table(ioc)
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$text)))}
df_ioc1 <- data.frame(ioc1 = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_ioc1) <- igo
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_ioc2 <- data.frame(ioc2 = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_ioc2) <- igo
df_ioc <- cbind(df_ioc1, df_ioc2)
df_ioc$ioc1 + df_ioc$ioc2
df_ioc %>% mutate(ioc = ioc1 + ioc2)
df_ioc %>% mutate(ioc = ioc1 + ioc2) %>% select(ioc)
df_ioc <- df_ioc %>% mutate(ioc = ioc1 + ioc2) %>% select(ioc)
isa <- read.csv("out_isa.csv")
DT <- as.data.table(isa)
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$text)))}
df_isa1 <- data.frame(isa1 = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_isa1) <- igo
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_isa2 <- data.frame(isa2 = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_isa2) <- igo
df_isa <- cbind(df_isa1, df_isa2)
df_isa <- df_isa %>% mutate(isa = isa1 + isa2) %>% select(isa)
isa <- read.csv("out_isa.csv")
DT <- as.data.table(isa)
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$text)))}
df_isa1 <- data.frame(isa1 = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_isa1) <- igo
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_isa2 <- data.frame(isa2 = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_isa2) <- igo
df_isa <- cbind(df_isa1, df_isa2)
View(df_isa)
df_isa <- df_isa %>% mutate(isa = isa1 + isa2) %>% select(isa)
unep <- read.csv("out_unep.csv")
DT <- as.data.table(unep)
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$text)))}
df_unep1 <- data.frame(unep1 = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_unep1) <- igo
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_unep2 <- data.frame(unep2 = matrix(unlist(x), nrow=length(x), byrow=T))
row.names(df_unep2) <- igo
df_unep <- cbind(df_unep1, df_unep2)
df_unep <- df_unep %>% mutate(unep = unep1 + unep2) %>% select(unep)
inc_net <- cbind(df_ioc, df_isa, df_unep)
net <- graph_from_incidence_matrix(inc_net)
plot(net)
View(inc_net)
View(df_ioc)
#################### IOC
ioc <- read.csv("out_ioc.csv")
DT <- as.data.table(ioc)
#text
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$text)))}
df_ioc1 <- data.frame(ioc1 = matrix(unlist(x), nrow=length(x), byrow=T))
#links
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_ioc2 <- data.frame(ioc2 = matrix(unlist(x), nrow=length(x), byrow=T))
df_ioc <- cbind(df_ioc1, df_ioc2)
df_ioc <- df_ioc %>% mutate(ioc = ioc1 + ioc2) %>% select(ioc)
row.names(df_ioc) <- igo
########################### ISA
isa <- read.csv("out_isa.csv")
DT <- as.data.table(isa)
# text
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$text)))}
df_isa1 <- data.frame(isa1 = matrix(unlist(x), nrow=length(x), byrow=T))
# link
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_isa2 <- data.frame(isa2 = matrix(unlist(x), nrow=length(x), byrow=T))
df_isa <- cbind(df_isa1, df_isa2)
df_isa <- df_isa %>% mutate(isa = isa1 + isa2) %>% select(isa)
row.names(df_isa) <- igo
######################## UNEP
unep <- read.csv("out_unep.csv")
DT <- as.data.table(unep)
# text
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$text)))}
df_unep1 <- data.frame(unep1 = matrix(unlist(x), nrow=length(x), byrow=T))
# links
x <- c()
for (i in igo){ x = c(x, igo = length(grep(i, DT$link)))}
df_unep2 <- data.frame(unep2 = matrix(unlist(x), nrow=length(x), byrow=T))
df_unep <- cbind(df_unep1, df_unep2)
df_unep <- df_unep %>% mutate(unep = unep1 + unep2) %>% select(unep)
row.names(df_unep) <- igo
inc_net <- cbind(df_ioc, df_isa, df_unep)
View(inc_net)
net <- graph_from_incidence_matrix(inc_net)
net <- graph_from_incidence_matrix(inc_net)
plot(net)
Isolated = which(degree(net)==0)
net2 = delete.vertices(net, Isolated)
plot(net2)
